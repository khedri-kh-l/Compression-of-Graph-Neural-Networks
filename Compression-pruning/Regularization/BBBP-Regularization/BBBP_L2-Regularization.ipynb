{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ed96ae",
   "metadata": {},
   "source": [
    "L2-Regularization Method on The Blood-brain barrier penetration (BBBP)\n",
    "--------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569199c6",
   "metadata": {},
   "source": [
    "### All libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefb22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "import statistics as stat\n",
    "import psutil\n",
    "import itertools\n",
    "import tracemalloc\n",
    "import gc\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from  utils import *\n",
    "\n",
    "#********************************************************#\n",
    "'''\n",
    "load_dataset contain lots of functions for loading several datasets and \n",
    "also there is a function as name get_ dataloader for generating a\n",
    "dictionary of training, validation, and testing dataLoader.\n",
    "'''\n",
    "from load_dataset import get_dataset, get_dataloader\n",
    "\n",
    "#********************************************************#\n",
    "'''\n",
    "As we need several arguments for training process, we store all argument in configure file. \n",
    "For using this file, you need the library'Typed Argument Parser (Tap). So you need 'pip install typed-argument-parser'. \n",
    "'''\n",
    "from Configures import data_args, train_args, model_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097fb19c",
   "metadata": {},
   "source": [
    "### Regularization Rate\n",
    "#### Regularization rates range from the following numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c86bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1e2, 1e3, 1e6\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7838a",
   "metadata": {},
   "source": [
    "### Functions for Measuring criterias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e331339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the total number of parameters of model\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    num_counted_elements = 0\n",
    "    for param in model.parameters():\n",
    "        if count_nonzero_only:\n",
    "            num_counted_elements += param.count_nonzero()\n",
    "        else:\n",
    "            num_counted_elements += param.numel()\n",
    "    return num_counted_elements\n",
    "\n",
    "# Function to get CPU usage\n",
    "def get_cpu_usage():\n",
    "    return psutil.cpu_percent(interval=1)\n",
    "\n",
    "\n",
    "\n",
    "# Function to approximate power consumption (Assume some average power usage per CPU percentage point)\n",
    "def estimate_power_usage(cpu_usage):\n",
    "    base_power_usage = 10  # Assumed base power usage in watts\n",
    "    power_per_percent = 0.5  # Assumed additional watts per CPU usage percent\n",
    "    return base_power_usage + (power_per_percent * cpu_usage)\n",
    "\n",
    "# The model size based on the number of parameters\n",
    "def get_model_size_param(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    return get_num_parameters(model, count_nonzero_only) * data_width\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8158a95b",
   "metadata": {},
   "source": [
    "### start loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923ed963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbbp\n",
      "/datasets\n"
     ]
    }
   ],
   "source": [
    "print(data_args.dataset_name)\n",
    "print(data_args.dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3de96ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(data_args.dataset_dir, data_args.dataset_name)\n",
    "input_dim = dataset.num_node_features\n",
    "output_dim = int(dataset.num_classes)\n",
    "\n",
    "\n",
    "print(input_dim)\n",
    "print(output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f41cf",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c01c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphs 2050, avg_nodes23.9356, avg_edge_index_25.8151\n",
      "The total num of dataset is 2050\n"
     ]
    }
   ],
   "source": [
    "avg_nodes = 0.0\n",
    "avg_edge_index = 0.0\n",
    "for i in range(len(dataset)):\n",
    "    avg_nodes += dataset[i].x.shape[0]\n",
    "    avg_edge_index += dataset[i].edge_index.shape[1]\n",
    "avg_nodes /= len(dataset)\n",
    "avg_edge_index /= len(dataset)\n",
    "print(f\"graphs {len(dataset)}, avg_nodes{avg_nodes :.4f}, avg_edge_index_{avg_edge_index/2 :.4f}\")\n",
    "\n",
    "best_acc = 0.0\n",
    "data_size = len(dataset)\n",
    "print(f'The total num of dataset is {data_size}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45512936",
   "metadata": {},
   "source": [
    "### Preprocessing and cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f2355e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of graphs after cleaning dataset is: 2039\n"
     ]
    }
   ],
   "source": [
    "#cleaned_dataset = [graph for graph in dataset if graph.edge_index.numpy()!=[]]\n",
    "cleaned_dataset = [graph for graph in dataset if graph.edge_index.numpy().size> 0]\n",
    "cleaned_dataset_len=len(cleaned_dataset)\n",
    "print(f'The number of graphs after cleaning dataset is: {cleaned_dataset_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93720bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader=get_dataloader(cleaned_dataset, batch_size=train_args.batch_size, random_split_flag=True, data_split_ratio=[0.8, 0.1, 0.1], seed=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca2b39",
   "metadata": {},
   "source": [
    "### Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be25f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCN import GCNNet\n",
    "\n",
    "def get_model(input_dim, output_dim, model_args):\n",
    "    if model_args.model_name.lower() == 'gcn':\n",
    "        return GCNNet(input_dim, output_dim, model_args)\n",
    "    elif model_args.model_name.lower() == 'gat':\n",
    "        return GATNet(input_dim, output_dim, model_args)\n",
    "    elif model_args.model_name.lower() == 'gin':\n",
    "        return GINNet(input_dim, output_dim, model_args)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "\n",
    "class GnnBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GnnBase, self).__init__()\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.to(self.device)\n",
    "        logits, prob, emb = self.model(data)\n",
    "        return logits, prob, emb\n",
    "\n",
    "    def update_state_dict(self, state_dict):\n",
    "        original_state_dict = self.state_dict()\n",
    "        loaded_state_dict = dict()\n",
    "        for k, v in state_dict.items():\n",
    "            if k in original_state_dict.keys():\n",
    "                loaded_state_dict[k] = v\n",
    "        self.load_state_dict(loaded_state_dict)\n",
    "\n",
    "    def to_device(self):\n",
    "        self.to(self.device)\n",
    "\n",
    "    def save_state_dict(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class GnnNets(GnnBase):\n",
    "    def __init__(self, input_dim, output_dim, model_args):\n",
    "        super(GnnNets, self).__init__()\n",
    "        self.model = get_model(input_dim, output_dim, model_args)\n",
    "        self.device = model_args.device\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.to(self.device)\n",
    "        logits, prob, emb = self.model(data)\n",
    "        return logits, prob, emb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73ee57",
   "metadata": {},
   "source": [
    "### Functions requirement training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2c39753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_GC(eval_dataloader,model, criterion):\n",
    "    acc = []\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            logits, probs, _ = model(batch)\n",
    "            loss = criterion(logits, batch.y)\n",
    "\n",
    "            ## record\n",
    "            _, prediction = torch.max(logits, -1)\n",
    "            loss_list.append(loss.item())\n",
    "            acc.append(prediction.eq(batch.y).cpu().numpy())\n",
    "\n",
    "        eval_state = {'loss': np.average(loss_list),\n",
    "                      'acc': np.concatenate(acc, axis=0).mean()}\n",
    "\n",
    "    return eval_state\n",
    "\n",
    "\n",
    "def test_GC(test_dataloader,model, criterion):\n",
    "    acc = []\n",
    "    loss_list = []\n",
    "    pred_probs = []\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            logits, probs, _ = model(batch)\n",
    "            loss = criterion(logits, batch.y)\n",
    "\n",
    "            # record\n",
    "            _, prediction = torch.max(logits, -1)\n",
    "            loss_list.append(loss.item())\n",
    "            acc.append(prediction.eq(batch.y).cpu().numpy())\n",
    "            predictions.append(prediction)\n",
    "            pred_probs.append(probs)\n",
    "\n",
    "    test_state = {'loss': np.average(loss_list),\n",
    "                  'acc': np.average(np.concatenate(acc, axis=0).mean())}\n",
    "\n",
    "    pred_probs = torch.cat(pred_probs, dim=0).cpu().detach().numpy()\n",
    "    predictions = torch.cat(predictions, dim=0).cpu().detach().numpy()\n",
    "    return test_state, pred_probs, predictions\n",
    "\n",
    "def train(l2):\n",
    "    logits, probs, _ = model(batch)\n",
    "    loss = criterion(logits, batch.y)\n",
    "    l2_reg = torch.tensor(0.)\n",
    "    for param in model.parameters():\n",
    "        l2_reg += torch.norm(param)\n",
    "\n",
    "    # Combine the loss function with L2 regularization\n",
    "    loss += (l2 * l2_reg)\n",
    "    \n",
    "    # optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=2.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    ## record\n",
    "    _, prediction = torch.max(logits, -1)\n",
    "    loss_list.append(loss.item())\n",
    "    acc.append(prediction.eq(batch.y).cpu().numpy())\n",
    "    \n",
    "  \n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f7ea44",
   "metadata": {},
   "source": [
    "### save path for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39ac0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "if not os.path.isdir(os.path.join('checkpoint', data_args.dataset_name)):\n",
    "    os.mkdir(os.path.join('checkpoint', f\"{data_args.dataset_name}\"))\n",
    "ckpt_dir = f\"./checkpoint/{data_args.dataset_name}/\"\n",
    "\n",
    "\n",
    "\n",
    "def save_best(ckpt_dir, epoch, state, model_name, eval_acc, is_best, is_reg):\n",
    "    print('saving....')\n",
    "    model.to_device()\n",
    "    state_save = {\n",
    "        'net':state,\n",
    "        'epoch':epoch,\n",
    "        'acc': eval_acc \n",
    "        }\n",
    "    best_pth_name = f'{model_name}_best.pth'\n",
    "    reg_pth_name = f'{model_name}_reg_best.pth'\n",
    "    \n",
    "  \n",
    "    if is_reg & is_best:\n",
    "        ckpt_path = os.path.join(ckpt_dir, reg_pth_name) \n",
    "        torch.save(state_save, ckpt_path)\n",
    "    \n",
    "     \n",
    "    if is_reg == False & is_best:\n",
    "        ckpt_path = os.path.join(ckpt_dir, best_pth_name)  \n",
    "        torch.save(state_save, ckpt_path)\n",
    "           \n",
    "        \n",
    "    model.to_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f50ee53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84a2b66b",
   "metadata": {},
   "source": [
    "### Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c70630",
   "metadata": {},
   "source": [
    "#### Setting Regularization rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6a64522",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is a dictionary to save all measurements. Aftre measuring, we can compute mean and std of each item.\n",
    "Eva_final=dict()\n",
    "\n",
    "# The following are all list of criteria for measurements. \n",
    "# We collect all desired datas of each list across iterations. \n",
    "# Then, we compute average and std of each list.\n",
    "\n",
    "#Base model\n",
    "Base_model_accuracy=[]\n",
    "T_base_model=[]\n",
    "Num_parm_base_model=[]\n",
    "Base_model_size=[]\n",
    "Base_Energy_Consumption=[]\n",
    "Base_Cpu_Usage=[]\n",
    "Base_Memory_Usage=[]\n",
    "\n",
    "#regularized model\n",
    "Reg_model_accuracy=[]\n",
    "T_Reg_model=[]\n",
    "Num_parm_Reg_model=[]\n",
    "Reg_model_size=[]\n",
    "Reg_Energy_Consumption=[]\n",
    "Reg_Cpu_Usage=[]\n",
    "Reg_Memory_Usage=[]\n",
    "\n",
    "# Here is the dictionary to record the list of all measurements\n",
    "Eva_measure={'base model accuracy':Base_model_accuracy,\n",
    "            'time inference of base model':T_base_model,\n",
    "            'number parmameters of base model':Num_parm_base_model,\n",
    "            'base model size':Base_model_size,\n",
    "            'energy consumption of base model':Base_Energy_Consumption,\n",
    "            'cpu usage of base model':Base_Cpu_Usage,\n",
    "            'memory usage of base model':Base_Memory_Usage,\n",
    "            'regularized model accuracy': Reg_model_accuracy,\n",
    "            'time inference of regularized model':T_Reg_model,\n",
    "            'number parmameters of regularized model':Num_parm_Reg_model,\n",
    "            'regularized model size':Reg_model_size,\n",
    "            'energy consumption of regularized model':Reg_Energy_Consumption,\n",
    "            'cpu usage of regularized model':Reg_Cpu_Usage,\n",
    "            'memory usage of regularized model':Reg_Memory_Usage\n",
    "            }\n",
    "\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11174cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regularization Rate\n",
    "l2_lambda = 0.9\n",
    "\n",
    "# The number of epoch\n",
    "num_epochs=100\n",
    "# The number of iteration\n",
    "num_iterations=10\n",
    "# Parameter for early stopping\n",
    "train_args.early_stopping=num_epochs*0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4767c7",
   "metadata": {},
   "source": [
    "### Training, and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5aab1777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation before regularization \n",
      "Starting training...\n",
      "The regularization rate is :0\n",
      "Eval Epoch: 0 | Loss: 0.542 | Acc: 0.754\n",
      "saving....\n",
      "saving....\n",
      "Eval Epoch: 5 | Loss: 0.473 | Acc: 0.808\n",
      "saving....\n",
      "saving....\n",
      "Eval Epoch: 10 | Loss: 0.457 | Acc: 0.788\n",
      "saving....\n",
      "Eval Epoch: 15 | Loss: 0.417 | Acc: 0.847\n",
      "saving....\n",
      "*****Results of base model*********\n",
      "base model has accuracy on test set=0.80%\n",
      "base model has size=141721.00 bytes\n",
      "The time inference of base model is =2.1644885999849066\n",
      "The number of parametrs of base model is:34524\n",
      "Energy Consumption : 120.346\n",
      "total memory usage of base model':25760 \n",
      "cpu usage of base model':89.400 %\n",
      "________*******************************_____________\n",
      "Regularized Model\n",
      "The regularization rate is :100000\n",
      "Eval Epoch: 0 | Loss: 0.693 | Acc: 0.754\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "Eval Epoch: 5 | Loss: 0.693 | Acc: 0.754\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "Eval Epoch: 10 | Loss: 0.693 | Acc: 0.246\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "Eval Epoch: 15 | Loss: 0.693 | Acc: 0.754\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "****************Result of regularized model ******************\n",
      "100000 regularized model has accuracy on test set=0.28%\n",
      "100000 regularized model has size=141761.00 bit\n",
      "The time inference of 100000 regularized model is =2.1622111999895424\n",
      "The number of parametrs of 100000 regularized model is:34562\n",
      "Energy Consumption of 100000 regularized model: 92.543\n",
      "total memory usage of 100000 regularized model':23462 \n",
      "cpu usage of 100000 regularized model':69.200 %\n",
      "Training and evaluation before regularization \n",
      "Starting training...\n",
      "The regularization rate is :0\n",
      "Eval Epoch: 0 | Loss: 0.545 | Acc: 0.754\n",
      "saving....\n",
      "Eval Epoch: 5 | Loss: 0.479 | Acc: 0.818\n",
      "saving....\n",
      "saving....\n",
      "Eval Epoch: 10 | Loss: 0.459 | Acc: 0.837\n",
      "saving....\n",
      "Eval Epoch: 15 | Loss: 0.458 | Acc: 0.798\n",
      "saving....\n",
      "*****Results of base model*********\n",
      "base model has accuracy on test set=0.78%\n",
      "base model has size=141721.00 bytes\n",
      "The time inference of base model is =2.177943199989386\n",
      "The number of parametrs of base model is:34524\n",
      "Energy Consumption : 87.444\n",
      "total memory usage of base model':26136 \n",
      "cpu usage of base model':60.500 %\n",
      "________*******************************_____________\n",
      "Regularized Model\n",
      "The regularization rate is :100000\n",
      "Eval Epoch: 0 | Loss: 0.693 | Acc: 0.754\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "Eval Epoch: 5 | Loss: 0.694 | Acc: 0.246\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "Eval Epoch: 10 | Loss: 0.693 | Acc: 0.754\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "Eval Epoch: 15 | Loss: 0.692 | Acc: 0.754\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "saving....\n",
      "****************Result of regularized model ******************\n",
      "100000 regularized model has accuracy on test set=0.28%\n",
      "100000 regularized model has size=141761.00 bit\n",
      "The time inference of 100000 regularized model is =2.1747317999834195\n",
      "The number of parametrs of 100000 regularized model is:34562\n",
      "Energy Consumption of 100000 regularized model: 65.024\n",
      "total memory usage of 100000 regularized model':24331 \n",
      "cpu usage of 100000 regularized model':33.100 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(num_iterations):\n",
    "        print('________________________________________________')\n",
    "        print('************************************************')\n",
    "        \n",
    "        print(f'Training and evaluation before regularization ')\n",
    "        print(\"Starting training...\")\n",
    "\n",
    "        model = GnnNets(input_dim, output_dim, model_args)\n",
    "        model.to_device()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = Adam(model.parameters(), lr=train_args.learning_rate, weight_decay=train_args.weight_decay)\n",
    "\n",
    "       \n",
    "        Eva=dict()# It is a dictionary to arrange output of this iteration\n",
    "        best_acc=0  \n",
    "        is_reg=False\n",
    "        reg_rate=0\n",
    "            \n",
    "       \n",
    "        #Training base model\n",
    "        print(f\"The regularization rate is :{reg_rate}\")\n",
    "        for epoch in range(num_epochs):  \n",
    "            acc=[]\n",
    "            loss_list = []\n",
    "            model.train()\n",
    "            for batch in dataloader['train']:\n",
    "                acc=train(reg_rate)        \n",
    "\n",
    "            eval_state = evaluate_GC(dataloader['eval'], model, criterion)\n",
    "            acc_eval=eval_state['acc']\n",
    "            # report train msg\n",
    "            if epoch % 20 == 0:   \n",
    "                print(f\"Eval Epoch: {epoch} | Loss: {eval_state['loss']:.3f} | Acc: {eval_state['acc']:.3f}\")\n",
    "\n",
    "\n",
    "            # only save the best model\n",
    "            if eval_state['acc'] > best_acc:\n",
    "                early_stop_count = 0\n",
    "            else:\n",
    "                early_stop_count += 1\n",
    "\n",
    "            if early_stop_count > train_args.early_stopping:\n",
    "                break\n",
    "            is_best = (eval_state['acc'] > best_acc)\n",
    "            if is_best:\n",
    "                best_acc = eval_state['acc']\n",
    "                early_stop_count = 0\n",
    "                    \n",
    "            if is_best or epoch % train_args.save_epoch == 0:\n",
    "                 save_best(ckpt_dir, epoch, model.state_dict(), model_args.model_name, eval_state['acc'], is_best, is_reg)   \n",
    "                                      \n",
    "\n",
    "\n",
    "\n",
    "        #### load the best model\n",
    "        base_model_path = os.path.join(ckpt_dir, f'{model_args.model_name}_best.pth') \n",
    "        checkpoint = torch.load(base_model_path)\n",
    "        model.load_state_dict(checkpoint['net'])\n",
    "        recover_model = lambda: model.load_state_dict(checkpoint['net'])\n",
    "\n",
    "        # Start monitoring CPU and memory usage, model size, number of parametes, time inference and  power consumption\n",
    "        gc.collect()\n",
    "        time.sleep(5)  # Add a 5-second delay to stabilize the initial state\n",
    "        tracemalloc.start()  # Start tracking memory allocations\n",
    "        snapshot_before = tracemalloc.take_snapshot()#take a snapshot of the current memory state before starting the measurement.\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        initial_cpu_usage = get_cpu_usage()\n",
    "        power_usage = estimate_power_usage(initial_cpu_usage)\n",
    "\n",
    "        test_state, _, _ = test_GC(dataloader['test'], model, criterion)\n",
    "        base_model_accuracy= test_state['acc']\n",
    "\n",
    "        base_cpu_usage = get_cpu_usage()\n",
    "        t1 = time.perf_counter()\n",
    "        t_base_model=t1-t0\n",
    "\n",
    "        snapshot_after = tracemalloc.take_snapshot()\n",
    "        tracemalloc.stop()\n",
    "        top_stats = snapshot_after.compare_to(snapshot_before, 'lineno')\n",
    "\n",
    "        base_total_memory_diff = sum([stat.size_diff for stat in top_stats])\n",
    "        \n",
    "        base_energy_consumption = power_usage * t_base_model\n",
    "        # model size\n",
    "        base_model_size = os.path.getsize(base_model_path)\n",
    "        # number of parameters\n",
    "        num_parm_base_model=get_num_parameters(model, count_nonzero_only=True)\n",
    "\n",
    "        gc.collect()\n",
    "        time.sleep(5) \n",
    "        \n",
    "        print(f'*****Results of base model*********')\n",
    "\n",
    "        print(f\"base model has accuracy on test set={base_model_accuracy:.2f}%\")\n",
    "        print(f\"base model has size={base_model_size:.2f} bytes\")\n",
    "        print(f\"The time inference of base model is ={t_base_model}\") \n",
    "        print(f\"The number of parametrs of base model is:{num_parm_base_model}\") \n",
    "\n",
    "        print(f\"Energy Consumption : {base_energy_consumption:.3f}\")\n",
    "        print(f\"total memory usage of base model':{base_total_memory_diff} \")\n",
    "        print(f\"cpu usage of base model':{base_cpu_usage:.3f} %\")\n",
    "\n",
    "\n",
    "        #Update Eva dictionary\n",
    "        Eva.update({'base model accuracy': base_model_accuracy,\n",
    "                    'time inference of base model': t_base_model,\n",
    "                    'number parmameters of base model': num_parm_base_model,\n",
    "                    'size of base model': base_model_size, \n",
    "                    'energy consumption of base model':base_energy_consumption,\n",
    "                    'total memory usage of base model':base_total_memory_diff,\n",
    "                    'cpu usage of base model':base_cpu_usage\n",
    "                   })\n",
    "\n",
    "        gc.collect()\n",
    "        time.sleep(5)  \n",
    "\n",
    "        #### Regularization of the Model\n",
    "        gc.collect()\n",
    "        time.sleep(5)   \n",
    "\n",
    "        print('________*******************************_____________')\n",
    "        print(f'Regularized Model')\n",
    "\n",
    "        best_reg_checkpoint = dict()\n",
    "        best_reg_acc = 0\n",
    "        is_reg=True\n",
    "        reg_rate=l2_lambda\n",
    "            \n",
    "        \n",
    "        model = GnnNets(input_dim, output_dim, model_args)\n",
    "        model.to_device()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = Adam(model.parameters(), lr=train_args.learning_rate, weight_decay=train_args.weight_decay)\n",
    "\n",
    "        print(f\"The regularization rate is :{reg_rate}\")\n",
    "        for epoch in range(num_epochs):\n",
    "            # At the end of each train iteration, we have to apply the pruning mask\n",
    "            #    to keep the model sparse during the training\n",
    "            acc=[]\n",
    "            loss_list = []\n",
    "\n",
    "            for batch in dataloader['train']:\n",
    "                acc=train(reg_rate)       \n",
    "\n",
    "            eval_state = evaluate_GC(dataloader['eval'], model, criterion)\n",
    "            acc_eval=eval_state['acc']\n",
    "\n",
    "            # report train msg\n",
    "            if epoch % 5 == 0:   \n",
    "                print(f\"Eval Epoch: {epoch} | Loss: {eval_state['loss']:.3f} | Acc: {eval_state['acc']:.3f}\")\n",
    "\n",
    "\n",
    "            # only save the best model\n",
    "            if eval_state['acc'] > best_reg_acc :\n",
    "                early_stop_count = 0\n",
    "            else:\n",
    "                early_stop_count += 1\n",
    "\n",
    "            if early_stop_count > train_args.early_stopping:\n",
    "                break\n",
    "            is_best = (eval_state['acc'] > best_reg_acc )\n",
    "           \n",
    "            if is_best:\n",
    "                best_acc = eval_state['acc']\n",
    "                early_stop_count = 0\n",
    "               \n",
    "          \n",
    "           \n",
    "            if is_best or epoch % train_args.save_epoch == 0:\n",
    "                \n",
    "                save_best(ckpt_dir, epoch, model.state_dict(), model_args.model_name, eval_state['acc'], is_best, is_reg)\n",
    "\n",
    "\n",
    "        #### load the best regularized model\n",
    "        reg_pth_name = f'{model_args.model_name}_reg_best.pth'\n",
    "        reg_model_path = os.path.join(ckpt_dir, reg_pth_name) \n",
    "        checkpoint = torch.load(reg_model_path)\n",
    "        model.load_state_dict(checkpoint['net'])\n",
    "        recover_model = lambda:model.load_state_dict(checkpoint['net'])\n",
    "\n",
    "\n",
    "        # Result of regularization\n",
    "      \n",
    "\n",
    "        gc.collect()\n",
    "        time.sleep(5)  \n",
    "        tracemalloc.start() \n",
    "        snapshot_before = tracemalloc.take_snapshot()\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "        initial_cpu_usage = get_cpu_usage()\n",
    "        power_usage = estimate_power_usage(initial_cpu_usage)\n",
    "\n",
    "        test_state, _, _ = test_GC(dataloader['test'], model, criterion)\n",
    "        regularized_model_accuracy= test_state['acc']\n",
    "\n",
    "        regularized_cpu_usage = get_cpu_usage()\n",
    "        t1 = time.perf_counter()\n",
    "        t_regularized_model=t1-t0\n",
    "\n",
    "        snapshot_after = tracemalloc.take_snapshot()\n",
    "        tracemalloc.stop()\n",
    "        top_stats = snapshot_after.compare_to(snapshot_before, 'lineno')\n",
    "\n",
    "        regularized_total_memory_diff = sum([stat.size_diff for stat in top_stats])\n",
    "        regularized_energy_consumption = power_usage * t_regularized_model\n",
    "        regularized_model_size = os.path.getsize( reg_model_path )\n",
    "        num_parm_regularized_model=get_num_parameters(model, count_nonzero_only=True)\n",
    "\n",
    "        gc.collect()\n",
    "        time.sleep(5)  # Add a 5-second delay to stabilize the initial state    \n",
    "        \n",
    " \n",
    "        \n",
    "        print('****************Result of regularized model ******************')\n",
    "    \n",
    "        \n",
    "        print(f\"{l2_lambda} regularized model has accuracy on test set={regularized_model_accuracy:.2f}%\")\n",
    "        print(f\"{l2_lambda} regularized model has size={regularized_model_size:.2f} bit\")\n",
    "        print(f\"The time inference of {l2_lambda} regularized model is ={t_regularized_model}\") \n",
    "        print(f\"The number of parametrs of {l2_lambda} regularized model is:{num_parm_regularized_model}\") \n",
    "\n",
    "        print(f\"Energy Consumption of {l2_lambda} regularized model: {regularized_energy_consumption:.3f}\")\n",
    "        print(f\"total memory usage of {l2_lambda} regularized model':{regularized_total_memory_diff} \")\n",
    "        print(f\"cpu usage of {l2_lambda} regularized model':{regularized_cpu_usage:.3f} %\")\n",
    "\n",
    "\n",
    "        #Update Eva dictionary\n",
    "        Eva.update({'regularized model accuracy': regularized_model_accuracy,\n",
    "                    'time inference of regularized model': t_regularized_model,\n",
    "                    'number parmameters of regularized model': num_parm_regularized_model,\n",
    "                    'size of regularized model': regularized_model_size, \n",
    "                    'energy consumption of regularized model':regularized_energy_consumption,\n",
    "                    'total memory usage of regularized model':regularized_total_memory_diff,\n",
    "                    'cpu usage of regularized model':regularized_cpu_usage\n",
    "                   })\n",
    "\n",
    "        gc.collect()\n",
    "        time.sleep(5)   \n",
    "\n",
    "        \n",
    "\n",
    "        Base_model_accuracy.append(Eva['base model accuracy'])\n",
    "        T_base_model.append(Eva['time inference of base model'])\n",
    "        Num_parm_base_model.append(int(Eva['number parmameters of base model']))\n",
    "        Base_model_size.append(int(Eva['size of base model']))\n",
    "        Base_Energy_Consumption.append(Eva['energy consumption of base model'])\n",
    "        Base_Cpu_Usage.append(Eva['cpu usage of base model'])\n",
    "        Base_Memory_Usage.append(Eva['total memory usage of base model'])\n",
    "\n",
    "        Reg_model_accuracy.append(Eva['regularized model accuracy'])\n",
    "        T_Reg_model.append(Eva['time inference of regularized model'])\n",
    "        Num_parm_Reg_model.append(int(Eva['number parmameters of regularized model']))\n",
    "        Reg_model_size.append(int(Eva['size of regularized model']))\n",
    "        Reg_Energy_Consumption.append(Eva['energy consumption of regularized model'])\n",
    "        Reg_Cpu_Usage.append(Eva['cpu usage of regularized model'])\n",
    "        Reg_Memory_Usage.append(Eva['total memory usage of regularized model'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7463a",
   "metadata": {},
   "source": [
    "### Computing Mean and Std of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a5438ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy is:0.789 ± 0.010\n",
      "Time inference of Base model :2.155 ± 0.047\n",
      "Time number of parameters of Base model :34522.833 ± 4.951\n",
      "The size of Base model :141721 bytes\n",
      "The energy consumption of Base model :54.147 ± 34.414 \n",
      "The CPU usage of Base model :27.258 ± 28.510 \n",
      "The memory usage of Base model :26127.583 ± 489.902 \n",
      "====================================================================================================\n",
      "Regularized model accuracy is:0.656 ± 0.226\n",
      "Time inference of Regularized model :2.139 ± 0.019\n",
      "Time number of parameters of Regularized model :34535.833 ± 19.922\n",
      "The size of Regularized model :141761.000 ± 0.000 bytes\n",
      "The energy consumption of Regularized model :44.075 ± 25.982 \n",
      "The CPU usage of Regularized model :16.442 ± 21.264 \n",
      "The memory usage of Regularized model :23575.833 ± 870.471 \n",
      "All measurement about regularization process of rate:100000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Ave of base model accuracy': 0.789,\n",
       " 'Std of base model accuracy': 0.01,\n",
       " 'Ave of time inference of base model': 2.155,\n",
       " 'Std of time inference of base model': 0.047,\n",
       " 'Ave of number parmameters of base model': 34522.833333333336,\n",
       " 'Std of number parmameters of base model': 4.951277765905637,\n",
       " 'Ave of base model size': 141721,\n",
       " 'Std of base model size': 0.0,\n",
       " 'Ave of energy consumption of base model': 54.14708325008978,\n",
       " 'Std of energy consumption of base model': 34.413852194055785,\n",
       " 'Ave of cpu usage of base model': 27.258333333333333,\n",
       " 'Std of cpu usage of base model': 28.510172294155367,\n",
       " 'Ave of memory usage of base model': 26127.583333333332,\n",
       " 'Std of memory usage of base model': 489.90248720505286,\n",
       " 'Ave of regularized model accuracy': 0.656,\n",
       " 'Std of regularized model accuracy': 0.226,\n",
       " 'Ave of time inference of regularized model': 2.139,\n",
       " 'Std of time inference of regularized model': 0.019,\n",
       " 'Ave of number parmameters of regularized model': 34535.833333333336,\n",
       " 'Std of number parmameters of regularized model': 19.92181688197108,\n",
       " 'Ave of regularized model size': 141761,\n",
       " 'Std of regularized model size': 0.0,\n",
       " 'Ave of energy consumption of regularized model': 44.075399951178404,\n",
       " 'Std of energy consumption of regularized model': 25.982079402131607,\n",
       " 'Ave of cpu usage of regularized model': 16.441666666666666,\n",
       " 'Std of cpu usage of regularized model': 21.264287531973043,\n",
       " 'Ave of memory usage of regularized model': 23575.833333333332,\n",
       " 'Std of memory usage of regularized model': 870.4709105194763}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eva_final=dict()\n",
    "base_model_accuracy_mean = stat.mean(Base_model_accuracy)\n",
    "base_model_accuracy_std =  stat.stdev(Base_model_accuracy)\n",
    "Eva_final.update({'Ave of base model accuracy':float(format(base_model_accuracy_mean, '.3f'))})\n",
    "Eva_final.update({'Std of base model accuracy':float(format(base_model_accuracy_std, '.3f'))})\n",
    "base_model_accuracy = \"{:.3f} ± {:.3f}\".format(base_model_accuracy_mean ,base_model_accuracy_std)\n",
    "print(f\"Base model accuracy is:{base_model_accuracy}\")\n",
    "\n",
    "                 \n",
    "t_base_model_mean =stat.mean(T_base_model)\n",
    "t_base_model_std =stat.stdev(T_base_model)  \n",
    "Eva_final.update({'Ave of time inference of base model':float(format(t_base_model_mean, '.3f'))})\n",
    "Eva_final.update({'Std of time inference of base model':float(format(t_base_model_std, '.3f'))})\n",
    "t_base_model = \"{:.3f} ± {:.3f}\".format(t_base_model_mean ,t_base_model_std)\n",
    "print(f\"Time inference of Base model :{t_base_model}\")\n",
    "\n",
    "\n",
    "num_parm_base_model_mean = stat.mean(Num_parm_base_model)\n",
    "num_parm_base_model_std = stat.stdev(Num_parm_base_model)\n",
    "Eva_final.update({'Ave of number parmameters of base model':num_parm_base_model_mean})\n",
    "Eva_final.update({'Std of number parmameters of base model':num_parm_base_model_std})\n",
    "num_parm_base_model = \"{:.3f} ± {:.3f}\".format(num_parm_base_model_mean ,num_parm_base_model_std)\n",
    "print(f\"Time number of parameters of Base model :{num_parm_base_model}\")\n",
    "\n",
    "base_model_size_mean = stat.mean(Base_model_size)\n",
    "base_model_size_std = stat.stdev(Base_model_size)\n",
    "Eva_final.update({'Ave of base model size':base_model_size_mean})\n",
    "Eva_final.update({'Std of base model size':base_model_size_std})\n",
    "base_model_size_model = \"{:.3f} ± {:.3f}\".format(base_model_size_mean ,base_model_size_std)\n",
    "print(f\"The size of Base model :{base_model_size} bytes\")\n",
    "\n",
    "\n",
    "base_energy_consumption_mean = stat.mean(Base_Energy_Consumption)\n",
    "base_energy_consumption_std = stat.stdev(Base_Energy_Consumption)\n",
    "Eva_final.update({'Ave of energy consumption of base model':base_energy_consumption_mean })\n",
    "Eva_final.update({'Std of energy consumption of base model':base_energy_consumption_std})\n",
    "base_energy_consumption = \"{:.3f} ± {:.3f}\".format(base_energy_consumption_mean ,base_energy_consumption_std)\n",
    "print(f\"The energy consumption of Base model :{base_energy_consumption} \")\n",
    "\n",
    "\n",
    "base_cpu_usage_mean = stat.mean(Base_Cpu_Usage)\n",
    "base_cpu_usage_std = stat.stdev(Base_Cpu_Usage)\n",
    "Eva_final.update({'Ave of cpu usage of base model':base_cpu_usage_mean})\n",
    "Eva_final.update({'Std of cpu usage of base model':base_cpu_usage_std})\n",
    "base_cpu_usage = \"{:.3f} ± {:.3f}\".format(base_cpu_usage_mean ,base_cpu_usage_std)\n",
    "print(f\"The CPU usage of Base model :{base_cpu_usage} \")\n",
    "\n",
    "\n",
    "base_memory_usage_mean = stat.mean(Base_Memory_Usage)\n",
    "base_memory_usage_std = stat.stdev(Base_Memory_Usage)\n",
    "Eva_final.update({'Ave of memory usage of base model':base_memory_usage_mean})\n",
    "Eva_final.update({'Std of memory usage of base model':base_memory_usage_std})\n",
    "base_memory_usage = \"{:.3f} ± {:.3f}\".format(base_memory_usage_mean ,base_memory_usage_std)\n",
    "print(f\"The memory usage of Base model :{base_memory_usage} \")\n",
    "\n",
    "print(100 * \"=\")\n",
    "####################################################\n",
    "\n",
    "reg_model_accuracy_mean =stat.mean(Reg_model_accuracy)\n",
    "reg_model_accuracy_std = stat.stdev(Reg_model_accuracy)\n",
    "Eva_final.update({'Ave of regularized model accuracy':float(format(reg_model_accuracy_mean, '.3f'))})\n",
    "Eva_final.update({'Std of regularized model accuracy':float(format(reg_model_accuracy_std, '.3f'))})\n",
    "reg_model_accuracy = \"{:.3f} ± {:.3f}\".format(reg_model_accuracy_mean ,reg_model_accuracy_std)\n",
    "print(f\"Regularized model accuracy is:{reg_model_accuracy}\")\n",
    "                 \n",
    "\n",
    "t_reg_model_mean = stat.mean(T_Reg_model)\n",
    "t_reg_model_std =stat.stdev(T_Reg_model)\n",
    "Eva_final.update({'Ave of time inference of regularized model':float(format(t_reg_model_mean, '.3f'))})\n",
    "Eva_final.update({'Std of time inference of regularized model':float(format(t_reg_model_std, '.3f'))})\n",
    "t_reg_model = \"{:.3f} ± {:.3f}\".format(t_reg_model_mean ,t_reg_model_std)\n",
    "print(f\"Time inference of Regularized model :{t_reg_model}\")\n",
    "\n",
    "num_parm_reg_model_mean = stat.mean(Num_parm_Reg_model)\n",
    "num_parm_reg_model_std = stat.stdev(Num_parm_Reg_model)\n",
    "Eva_final.update({'Ave of number parmameters of regularized model':num_parm_reg_model_mean})\n",
    "Eva_final.update({'Std of number parmameters of regularized model':num_parm_reg_model_std})\n",
    "num_parm_reg_model = \"{:.3f} ± {:.3f}\".format(num_parm_reg_model_mean ,num_parm_reg_model_std)\n",
    "print(f\"Time number of parameters of Regularized model :{num_parm_reg_model}\")\n",
    "\n",
    "reg_model_size_mean =stat.mean( Reg_model_size)\n",
    "reg_model_size_std = stat.stdev(Reg_model_size)\n",
    "Eva_final.update({'Ave of regularized model size':reg_model_size_mean})\n",
    "Eva_final.update({'Std of regularized model size':reg_model_size_std })\n",
    "reg_model_size = \"{:.3f} ± {:.3f}\".format(reg_model_size_mean ,reg_model_size_std)\n",
    "print(f\"The size of Regularized model :{reg_model_size} bytes\")\n",
    "\n",
    "reg_energy_consumption_mean = stat.mean(Reg_Energy_Consumption)\n",
    "reg_energy_consumption_std = stat.stdev(Reg_Energy_Consumption)\n",
    "Eva_final.update({'Ave of energy consumption of regularized model':reg_energy_consumption_mean })\n",
    "Eva_final.update({'Std of energy consumption of regularized model':reg_energy_consumption_std})\n",
    "reg_energy_consumption = \"{:.3f} ± {:.3f}\".format(reg_energy_consumption_mean ,reg_energy_consumption_std)\n",
    "print(f\"The energy consumption of Regularized model :{reg_energy_consumption} \")\n",
    "\n",
    "\n",
    "reg_cpu_usage_mean = stat.mean(Reg_Cpu_Usage)\n",
    "reg_cpu_usage_std = stat.stdev(Reg_Cpu_Usage)\n",
    "Eva_final.update({'Ave of cpu usage of regularized model':reg_cpu_usage_mean})\n",
    "Eva_final.update({'Std of cpu usage of regularized model':reg_cpu_usage_std})\n",
    "reg_cpu_usage = \"{:.3f} ± {:.3f}\".format(reg_cpu_usage_mean ,reg_cpu_usage_std)\n",
    "print(f\"The CPU usage of Regularized model :{reg_cpu_usage} \")\n",
    "\n",
    "\n",
    "reg_memory_usage_mean = stat.mean(Reg_Memory_Usage)\n",
    "reg_memory_usage_std = stat.stdev(Reg_Memory_Usage)\n",
    "#desc = \"{:.3f} ± {:.3f}\".format(acc_mean,acc_std)\n",
    "Eva_final.update({'Ave of memory usage of regularized model':reg_memory_usage_mean})\n",
    "Eva_final.update({'Std of memory usage of regularized model':reg_memory_usage_std})\n",
    "reg_memory_usage = \"{:.3f} ± {:.3f}\".format(reg_memory_usage_mean ,reg_memory_usage_std)\n",
    "print(f\"The memory usage of Regularized model :{reg_memory_usage} \")\n",
    "\n",
    "\n",
    "\n",
    "#################################\n",
    "\n",
    "\n",
    "print(f\"All measurement about regularization process of rate:{l2_lambda} \")   \n",
    "Eva_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ac07fd",
   "metadata": {},
   "source": [
    "### Recording results on txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f10bc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_name = 'BBBP'\n",
    "Pruning_Method='Regularization'\n",
    "max_epoch = 100\n",
    "resume = True\n",
    "result_folder ='pathresult/'\n",
    "if not os.path.exists(result_folder):\n",
    "    os.makedirs(result_folder)\n",
    "\n",
    "\n",
    "\n",
    "file_name = result_folder+Pruning_Method+'_'+'with rate of regularization of'+'_'+str(l2_lambda)+'_on_'+dataset_name+'_'+str(max_epoch)+'.txt'\n",
    "\n",
    "with open(file_name, 'w') as f:\n",
    "        f.write('%s:%s\\n'%('dataset_name', 'BBBP'))\n",
    "        f.write('%s:%s\\n'%('max_epoch', max_epoch))\n",
    "        f.write('%s:%s\\n'%('sparsity', l2_lambda))\n",
    "        for key, value in Eva_final.items():\n",
    "            f.write('%s:%s\\n'%(key, value))\n",
    "     \n",
    "        for key, value in Eva_measure.items():\n",
    "            f.write('%s:%s\\n' % (key, ','.join(map(str, value)))) \n",
    "       \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854611b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becde53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
